Log file created at: 2017/09/08 10:02:07
Running on machine: iiticubsrv017
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0908 10:02:07.234519 31309 net.cpp:42] Initializing net from parameters: 
name: "Zeiler_conv5"
input: "data"
input: "rois"
input_dim: 1
input_dim: 3
input_dim: 224
input_dim: 224
input_dim: 1
input_dim: 5
input_dim: 1
input_dim: 1
state {
  phase: TEST
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 6
    pooled_w: 6
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
    scale_train: false
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
    scale_train: false
  }
}
I0908 10:02:07.235129 31309 net.cpp:380] Input 0 -> data
I0908 10:02:07.235160 31309 net.cpp:380] Input 1 -> rois
I0908 10:02:07.235186 31309 layer_factory.hpp:74] Creating layer conv1
I0908 10:02:07.235200 31309 net.cpp:90] Creating Layer conv1
I0908 10:02:07.235205 31309 net.cpp:420] conv1 <- data
I0908 10:02:07.235216 31309 net.cpp:378] conv1 -> conv1
I0908 10:02:07.235231 31309 net.cpp:120] Setting up conv1
I0908 10:02:07.235625 31309 net.cpp:127] Top shape: 1 96 112 112 (1204224)
I0908 10:02:07.235646 31309 layer_factory.hpp:74] Creating layer relu1
I0908 10:02:07.235656 31309 net.cpp:90] Creating Layer relu1
I0908 10:02:07.235661 31309 net.cpp:420] relu1 <- conv1
I0908 10:02:07.235668 31309 net.cpp:367] relu1 -> conv1 (in-place)
I0908 10:02:07.235677 31309 net.cpp:120] Setting up relu1
I0908 10:02:07.235684 31309 net.cpp:127] Top shape: 1 96 112 112 (1204224)
I0908 10:02:07.235688 31309 layer_factory.hpp:74] Creating layer norm1
I0908 10:02:07.235699 31309 net.cpp:90] Creating Layer norm1
I0908 10:02:07.235703 31309 net.cpp:420] norm1 <- conv1
I0908 10:02:07.235709 31309 net.cpp:378] norm1 -> norm1
I0908 10:02:07.235718 31309 net.cpp:120] Setting up norm1
I0908 10:02:07.235759 31309 net.cpp:127] Top shape: 1 96 112 112 (1204224)
I0908 10:02:07.235762 31309 layer_factory.hpp:74] Creating layer pool1
I0908 10:02:07.235771 31309 net.cpp:90] Creating Layer pool1
I0908 10:02:07.235775 31309 net.cpp:420] pool1 <- norm1
I0908 10:02:07.235781 31309 net.cpp:378] pool1 -> pool1
I0908 10:02:07.235790 31309 net.cpp:120] Setting up pool1
I0908 10:02:07.235801 31309 net.cpp:127] Top shape: 1 96 57 57 (311904)
I0908 10:02:07.235805 31309 layer_factory.hpp:74] Creating layer conv2
I0908 10:02:07.235815 31309 net.cpp:90] Creating Layer conv2
I0908 10:02:07.235818 31309 net.cpp:420] conv2 <- pool1
I0908 10:02:07.235827 31309 net.cpp:378] conv2 -> conv2
I0908 10:02:07.235836 31309 net.cpp:120] Setting up conv2
I0908 10:02:07.249634 31309 net.cpp:127] Top shape: 1 256 29 29 (215296)
I0908 10:02:07.249645 31309 layer_factory.hpp:74] Creating layer relu2
I0908 10:02:07.249655 31309 net.cpp:90] Creating Layer relu2
I0908 10:02:07.249658 31309 net.cpp:420] relu2 <- conv2
I0908 10:02:07.249665 31309 net.cpp:367] relu2 -> conv2 (in-place)
I0908 10:02:07.249672 31309 net.cpp:120] Setting up relu2
I0908 10:02:07.249678 31309 net.cpp:127] Top shape: 1 256 29 29 (215296)
I0908 10:02:07.249682 31309 layer_factory.hpp:74] Creating layer norm2
I0908 10:02:07.249689 31309 net.cpp:90] Creating Layer norm2
I0908 10:02:07.249693 31309 net.cpp:420] norm2 <- conv2
I0908 10:02:07.249699 31309 net.cpp:378] norm2 -> norm2
I0908 10:02:07.249706 31309 net.cpp:120] Setting up norm2
I0908 10:02:07.249732 31309 net.cpp:127] Top shape: 1 256 29 29 (215296)
I0908 10:02:07.249735 31309 layer_factory.hpp:74] Creating layer pool2
I0908 10:02:07.249742 31309 net.cpp:90] Creating Layer pool2
I0908 10:02:07.249747 31309 net.cpp:420] pool2 <- norm2
I0908 10:02:07.249753 31309 net.cpp:378] pool2 -> pool2
I0908 10:02:07.249760 31309 net.cpp:120] Setting up pool2
I0908 10:02:07.249769 31309 net.cpp:127] Top shape: 1 256 15 15 (57600)
I0908 10:02:07.249773 31309 layer_factory.hpp:74] Creating layer conv3
I0908 10:02:07.249783 31309 net.cpp:90] Creating Layer conv3
I0908 10:02:07.249786 31309 net.cpp:420] conv3 <- pool2
I0908 10:02:07.249794 31309 net.cpp:378] conv3 -> conv3
I0908 10:02:07.249804 31309 net.cpp:120] Setting up conv3
I0908 10:02:07.269032 31309 net.cpp:127] Top shape: 1 384 15 15 (86400)
I0908 10:02:07.269057 31309 layer_factory.hpp:74] Creating layer relu3
I0908 10:02:07.269071 31309 net.cpp:90] Creating Layer relu3
I0908 10:02:07.269078 31309 net.cpp:420] relu3 <- conv3
I0908 10:02:07.269088 31309 net.cpp:367] relu3 -> conv3 (in-place)
I0908 10:02:07.269098 31309 net.cpp:120] Setting up relu3
I0908 10:02:07.269106 31309 net.cpp:127] Top shape: 1 384 15 15 (86400)
I0908 10:02:07.269110 31309 layer_factory.hpp:74] Creating layer conv4
I0908 10:02:07.269121 31309 net.cpp:90] Creating Layer conv4
I0908 10:02:07.269125 31309 net.cpp:420] conv4 <- conv3
I0908 10:02:07.269134 31309 net.cpp:378] conv4 -> conv4
I0908 10:02:07.269176 31309 net.cpp:120] Setting up conv4
I0908 10:02:07.295120 31309 net.cpp:127] Top shape: 1 384 15 15 (86400)
I0908 10:02:07.295133 31309 layer_factory.hpp:74] Creating layer relu4
I0908 10:02:07.295143 31309 net.cpp:90] Creating Layer relu4
I0908 10:02:07.295146 31309 net.cpp:420] relu4 <- conv4
I0908 10:02:07.295155 31309 net.cpp:367] relu4 -> conv4 (in-place)
I0908 10:02:07.295161 31309 net.cpp:120] Setting up relu4
I0908 10:02:07.295166 31309 net.cpp:127] Top shape: 1 384 15 15 (86400)
I0908 10:02:07.295169 31309 layer_factory.hpp:74] Creating layer conv5
I0908 10:02:07.295178 31309 net.cpp:90] Creating Layer conv5
I0908 10:02:07.295181 31309 net.cpp:420] conv5 <- conv4
I0908 10:02:07.295189 31309 net.cpp:378] conv5 -> conv5
I0908 10:02:07.295198 31309 net.cpp:120] Setting up conv5
I0908 10:02:07.310047 31309 net.cpp:127] Top shape: 1 256 15 15 (57600)
I0908 10:02:07.310061 31309 layer_factory.hpp:74] Creating layer relu5
I0908 10:02:07.310070 31309 net.cpp:90] Creating Layer relu5
I0908 10:02:07.310072 31309 net.cpp:420] relu5 <- conv5
I0908 10:02:07.310077 31309 net.cpp:367] relu5 -> conv5 (in-place)
I0908 10:02:07.310082 31309 net.cpp:120] Setting up relu5
I0908 10:02:07.310087 31309 net.cpp:127] Top shape: 1 256 15 15 (57600)
I0908 10:02:07.310091 31309 layer_factory.hpp:74] Creating layer roi_pool5
I0908 10:02:07.310098 31309 net.cpp:90] Creating Layer roi_pool5
I0908 10:02:07.310101 31309 net.cpp:420] roi_pool5 <- conv5
I0908 10:02:07.310104 31309 net.cpp:420] roi_pool5 <- rois
I0908 10:02:07.310111 31309 net.cpp:378] roi_pool5 -> pool5
I0908 10:02:07.310115 31309 net.cpp:120] Setting up roi_pool5
I0908 10:02:07.310119 31309 roi_pooling_layer.cpp:44] Spatial scale: 0.0625
I0908 10:02:07.310140 31309 net.cpp:127] Top shape: 1 256 6 6 (9216)
I0908 10:02:07.310143 31309 layer_factory.hpp:74] Creating layer fc6
I0908 10:02:07.310150 31309 net.cpp:90] Creating Layer fc6
I0908 10:02:07.310153 31309 net.cpp:420] fc6 <- pool5
I0908 10:02:07.310159 31309 net.cpp:378] fc6 -> fc6
I0908 10:02:07.310166 31309 net.cpp:120] Setting up fc6
I0908 10:02:07.380254 31309 net.cpp:127] Top shape: 1 4096 (4096)
I0908 10:02:07.380273 31309 layer_factory.hpp:74] Creating layer relu6
I0908 10:02:07.380290 31309 net.cpp:90] Creating Layer relu6
I0908 10:02:07.380293 31309 net.cpp:420] relu6 <- fc6
I0908 10:02:07.380300 31309 net.cpp:367] relu6 -> fc6 (in-place)
I0908 10:02:07.380306 31309 net.cpp:120] Setting up relu6
I0908 10:02:07.380311 31309 net.cpp:127] Top shape: 1 4096 (4096)
I0908 10:02:07.380313 31309 layer_factory.hpp:74] Creating layer drop6
I0908 10:02:07.380321 31309 net.cpp:90] Creating Layer drop6
I0908 10:02:07.380322 31309 net.cpp:420] drop6 <- fc6
I0908 10:02:07.380326 31309 net.cpp:367] drop6 -> fc6 (in-place)
I0908 10:02:07.380331 31309 net.cpp:120] Setting up drop6
I0908 10:02:07.380336 31309 net.cpp:127] Top shape: 1 4096 (4096)
I0908 10:02:07.380337 31309 layer_factory.hpp:74] Creating layer fc7
I0908 10:02:07.380343 31309 net.cpp:90] Creating Layer fc7
I0908 10:02:07.380345 31309 net.cpp:420] fc7 <- fc6
I0908 10:02:07.380349 31309 net.cpp:378] fc7 -> fc7
I0908 10:02:07.380355 31309 net.cpp:120] Setting up fc7
I0908 10:02:07.408033 31309 net.cpp:127] Top shape: 1 4096 (4096)
I0908 10:02:07.408051 31309 layer_factory.hpp:74] Creating layer relu7
I0908 10:02:07.408058 31309 net.cpp:90] Creating Layer relu7
I0908 10:02:07.408061 31309 net.cpp:420] relu7 <- fc7
I0908 10:02:07.408066 31309 net.cpp:367] relu7 -> fc7 (in-place)
I0908 10:02:07.408072 31309 net.cpp:120] Setting up relu7
I0908 10:02:07.408077 31309 net.cpp:127] Top shape: 1 4096 (4096)
I0908 10:02:07.408077 31309 layer_factory.hpp:74] Creating layer drop7
I0908 10:02:07.408083 31309 net.cpp:90] Creating Layer drop7
I0908 10:02:07.408084 31309 net.cpp:420] drop7 <- fc7
I0908 10:02:07.408088 31309 net.cpp:367] drop7 -> fc7 (in-place)
I0908 10:02:07.408092 31309 net.cpp:120] Setting up drop7
I0908 10:02:07.408095 31309 net.cpp:127] Top shape: 1 4096 (4096)
I0908 10:02:07.408097 31309 net.cpp:194] drop7 does not need backward computation.
I0908 10:02:07.408133 31309 net.cpp:194] relu7 does not need backward computation.
I0908 10:02:07.408134 31309 net.cpp:194] fc7 does not need backward computation.
I0908 10:02:07.408136 31309 net.cpp:194] drop6 does not need backward computation.
I0908 10:02:07.408138 31309 net.cpp:194] relu6 does not need backward computation.
I0908 10:02:07.408140 31309 net.cpp:194] fc6 does not need backward computation.
I0908 10:02:07.408143 31309 net.cpp:194] roi_pool5 does not need backward computation.
I0908 10:02:07.408145 31309 net.cpp:194] relu5 does not need backward computation.
I0908 10:02:07.408149 31309 net.cpp:194] conv5 does not need backward computation.
I0908 10:02:07.408150 31309 net.cpp:194] relu4 does not need backward computation.
I0908 10:02:07.408152 31309 net.cpp:194] conv4 does not need backward computation.
I0908 10:02:07.408154 31309 net.cpp:194] relu3 does not need backward computation.
I0908 10:02:07.408156 31309 net.cpp:194] conv3 does not need backward computation.
I0908 10:02:07.408159 31309 net.cpp:194] pool2 does not need backward computation.
I0908 10:02:07.408161 31309 net.cpp:194] norm2 does not need backward computation.
I0908 10:02:07.408164 31309 net.cpp:194] relu2 does not need backward computation.
I0908 10:02:07.408166 31309 net.cpp:194] conv2 does not need backward computation.
I0908 10:02:07.408185 31309 net.cpp:194] pool1 does not need backward computation.
I0908 10:02:07.408187 31309 net.cpp:194] norm1 does not need backward computation.
I0908 10:02:07.408190 31309 net.cpp:194] relu1 does not need backward computation.
I0908 10:02:07.408191 31309 net.cpp:194] conv1 does not need backward computation.
I0908 10:02:07.408193 31309 net.cpp:235] This network produces output fc7
I0908 10:02:07.408210 31309 net.cpp:492] Collecting Learning Rate and Weight Decay.
I0908 10:02:07.408216 31309 net.cpp:247] Network initialization done.
I0908 10:02:07.408217 31309 net.cpp:248] Memory required for data: 20490624
I0908 10:02:07.588995 31309 net.cpp:743] Ignoring source layer labels_input_2_split
I0908 10:02:07.589017 31309 net.cpp:746] Copying source layer conv1
I0908 10:02:07.589040 31309 net.cpp:746] Copying source layer relu1
I0908 10:02:07.589041 31309 net.cpp:746] Copying source layer norm1
I0908 10:02:07.589042 31309 net.cpp:746] Copying source layer pool1
I0908 10:02:07.589045 31309 net.cpp:746] Copying source layer conv2
I0908 10:02:07.589654 31309 net.cpp:746] Copying source layer relu2
I0908 10:02:07.589658 31309 net.cpp:746] Copying source layer norm2
I0908 10:02:07.589658 31309 net.cpp:746] Copying source layer pool2
I0908 10:02:07.589660 31309 net.cpp:746] Copying source layer conv3
I0908 10:02:07.590610 31309 net.cpp:746] Copying source layer relu3
I0908 10:02:07.590612 31309 net.cpp:746] Copying source layer conv4
I0908 10:02:07.591962 31309 net.cpp:746] Copying source layer relu4
I0908 10:02:07.591964 31309 net.cpp:746] Copying source layer conv5
I0908 10:02:07.592861 31309 net.cpp:746] Copying source layer relu5
I0908 10:02:07.592864 31309 net.cpp:746] Copying source layer roi_pool5
I0908 10:02:07.592866 31309 net.cpp:746] Copying source layer fc6
I0908 10:02:07.626750 31309 net.cpp:746] Copying source layer relu6
I0908 10:02:07.626761 31309 net.cpp:746] Copying source layer drop6
I0908 10:02:07.626763 31309 net.cpp:746] Copying source layer fc7
I0908 10:02:07.641127 31309 net.cpp:746] Copying source layer relu7
I0908 10:02:07.641137 31309 net.cpp:746] Copying source layer drop7
I0908 10:02:07.641139 31309 net.cpp:743] Ignoring source layer fc7_drop7_0_split
I0908 10:02:07.641141 31309 net.cpp:743] Ignoring source layer cls_score
I0908 10:02:07.641142 31309 net.cpp:743] Ignoring source layer cls_score_cls_score_0_split
I0908 10:02:07.641144 31309 net.cpp:743] Ignoring source layer bbox_pred
I0908 10:02:07.641146 31309 net.cpp:743] Ignoring source layer loss
I0908 10:02:07.641147 31309 net.cpp:743] Ignoring source layer accuarcy
I0908 10:02:07.641149 31309 net.cpp:743] Ignoring source layer loss_bbox
